{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01689563-18d3-4c6e-a3e4-292d90812719",
   "metadata": {},
   "source": [
    "# 序列到序列学习（seq2seq）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f739df6-42c0-4542-87ab-6c690594c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c7614a-0abc-4400-9aed-b27c14fbfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器。\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, ​**kwargs):\n",
    "        # 初始化父类（继承自d2l.Encoder框架）\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 创建词嵌入层：将词汇索引转换为密集向量\n",
    "        # vocab_size: 输入语言词汇表大小（如10000个词）\n",
    "        # embed_size: 每个词向量的维度（如512维）\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 创建GRU循环神经网络层\n",
    "        # embed_size: 输入特征维度（与嵌入层输出一致）\n",
    "        # num_hiddens: 隐藏层神经元数（如24个）\n",
    "        # num_layers: GRU堆叠层数（如2层）\n",
    "        # dropout: 层间随机失活率（防止过拟合）\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输入X形状：(batch_size, seq_length) 如(3,8)\n",
    "        \n",
    "        # 嵌入层处理：将词索引转换为密集向量\n",
    "        # 输出形状变为：(batch_size, seq_length, embed_size) 如(3,8,512)\n",
    "        X = self.embedding(X)\n",
    "        \n",
    "        # 维度置换：调整张量维度顺序以适应RNN输入要求\n",
    "        # permute(1,0,2)将维度从(batch,seq,embed)变为(seq,batch,embed)\n",
    "        # 因为PyTorch的RNN层要求输入形状为(seq_len, batch_size, input_size)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        \n",
    "        # 通过GRU网络处理时序数据\n",
    "        # output: 所有时间步的隐藏状态，形状(seq_len, batch_size, num_hiddens*D) \n",
    "        #         D=1（单向）或2（双向），此处默认单向\n",
    "        # state: 最后一个时间步的隐藏状态，形状(num_layers, batch_size, num_hiddens)\n",
    "        #        当num_layers=2时包含两个隐藏层的最终状态\n",
    "        output, state = self.rnn(X)\n",
    "        \n",
    "        # 返回编码器输出和最终状态（供解码器初始化用）\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f89d92-057a-41ac-b521-ec60ffdba0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648f7cd8-e2a0-4edb-b9f4-48e6fec7c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79dbe9b3-727f-4a4b-8321-63bc8b82c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络解码器。\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, ​**kwargs):\n",
    "        # 初始化父类（继承自d2l.Decoder框架）\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        # 创建词嵌入层：将目标语言词索引转换为密集向量\n",
    "        # vocab_size: 目标语言词汇表大小（如25000个词）\n",
    "        # embed_size: 每个词向量的维度（需与编码器设置一致）\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 创建带上下文拼接的GRU网络：\n",
    "        # 输入维度是embed_size + num_hiddens（将编码器上下文信息与当前词向量拼接）\n",
    "        # num_hiddens: 隐藏层维度需与编码器一致（如24）\n",
    "        # num_layers: GRU层数需与编码器一致（如2层）\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "        # 输出全连接层：将隐藏状态映射到目标语言词汇表维度\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        # 从编码器输出中提取最终隐藏状态作为解码器初始状态\n",
    "        # enc_outputs是元组(output, state)，其中state包含各层的最终隐藏状态\n",
    "        # 取[1]索引获取state，该状态是(num_layers, batch_size, num_hiddens)\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 输入X形状：(batch_size, seq_length) 如(3,7)\n",
    "        # 词嵌入处理，输出形状变为：(batch_size, seq_length, embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 维度置换：调整为(seq_length, batch_size, embed_size)\n",
    "        # 与编码器一致，满足PyTorch GRU输入格式要求\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 上下文扩展：获取编码器最后时刻最后一层的隐藏状态\n",
    "        # state[-1]的shape是(num_layers, batch_size, num_hiddens)，取最后一层\n",
    "        # repeat扩展至(seq_length, batch_size, num_hiddens)匹配时间步数\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        # 拼接词向量与上下文信息\n",
    "        # 在特征维度拼接，因此输入维度变为embed_size+num_hiddens\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        # GRU前向传播（同时传递初始状态）\n",
    "        # output形状：(seq_length, batch_size, num_hiddens)\n",
    "        # state形状：(num_layers, batch_size, num_hiddens)\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        # 全连接层预测词概率分布\n",
    "        # 先permute恢复为(batch_size, seq_length, vocab_size)\n",
    "        output = self.dense(output).permute(1, 0, 2)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0687023-f15a-4e52-abcb-fef437185ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "state = decoder.init_state(encoder(X))\n",
    "output, state = decoder(X, state)\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "385d65d3-9cb9-47fa-b977-3e62aceb7a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n应用场景说明：\\n1. 自然语言处理：处理不同长度句子时屏蔽padding位置\\n2. 时间序列预测：仅对有效历史数据进行处理\\n3. 注意力机制：防止关注到无效位置\\n\\n关键记忆点：\\n1. 维度操作技巧：\\n   - [None,:]将行向量变为(1, maxlen)\\n   - valid_len[:,None]将列向量变为(batch_size, 1)\\n   - 两者广播后得到(batch_size, maxlen)的布尔矩阵\\n\\n2. 设备一致性原则：\\n   - mask.device = X.device 确保张量在同一设备（CPU/GPU）\\n\\n3. 逆向思维运用：\\n   - 通过~mask取反选择需要屏蔽的位置\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项。\"\"\"\n",
    "    # 获取当前批次的最大序列长度（X的形状是(batch_size, seq_length)）\n",
    "    # 例如：X是形状(2,3)的张量时，maxlen=3\n",
    "    maxlen = X.size(1)\n",
    "    \n",
    "    # 创建序列位置索引矩阵\n",
    "    # torch.arange生成[0,1,2,...,maxlen-1]的行向量（通过[None,:]增加第0维度）\n",
    "    # 与valid_len[:,None]（列向量）进行广播比较，生成布尔掩码矩阵\n",
    "    # 例如valid_len=[1,2]时，生成mask=[[True,False,False],[True,True,False]]\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    \n",
    "    # 将掩码取反后赋值为指定值\n",
    "    # ~mask表示需要屏蔽的位置，例如mask为False的位置会被填充value\n",
    "    X[~mask] = value\n",
    "    \n",
    "    return X  # 返回处理后的张量，如输入[[1,2,3],[4,5,6]]变为[[1,0,0],[4,5,0]]\n",
    "\n",
    "\"\"\"\n",
    "应用场景说明：\n",
    "1. 自然语言处理：处理不同长度句子时屏蔽padding位置\n",
    "2. 时间序列预测：仅对有效历史数据进行处理\n",
    "3. 注意力机制：防止关注到无效位置\n",
    "\n",
    "关键记忆点：\n",
    "1. 维度操作技巧：\n",
    "   - [None,:]将行向量变为(1, maxlen)\n",
    "   - valid_len[:,None]将列向量变为(batch_size, 1)\n",
    "   - 两者广播后得到(batch_size, maxlen)的布尔矩阵\n",
    "\n",
    "2. 设备一致性原则：\n",
    "   - mask.device = X.device 确保张量在同一设备（CPU/GPU）\n",
    "\n",
    "3. 逆向思维运用：\n",
    "   - 通过~mask取反选择需要屏蔽的位置\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a256527e-7cb2-4e5b-b3da-267b478e5fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47ec7fc-34ae-464d-a4cb-a4e5945ee006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        # 初始化权重矩阵：创建与标签形状相同的全1张量\n",
    "        # 原理：所有时间步初始权重为1，后续通过valid_len屏蔽padding位置\n",
    "        # 记忆点：始终与label形状保持一致（batch_size, seq_length）\n",
    "        weights = torch.ones_like(label)\n",
    "        \n",
    "        # 应用序列遮蔽：将超出有效长度的位置权重置0\n",
    "        # 关键：sequence_mask函数\n",
    "        # 效果：例如valid_len=[2,4]时，保留前2/4个时间步的权重\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        \n",
    "        # 禁用默认的损失聚合方式：保留每个时间步的损失值\n",
    "        # 原理：父类CrossEntropyLoss默认会做mean/sum，这里需要逐个位置计算\n",
    "        self.reduction = 'none'\n",
    "        \n",
    "        # 计算未加权的交叉熵损失（注意维度调整）\n",
    "        # permute(0,2,1)将pred从(batch, seq, vocab)转为(batch, vocab, seq)\n",
    "        # 原因：CrossEntropyLoss要求class维度在第二位置\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss,\n",
    "                                self).forward(pred.permute(0, 2, 1), label)\n",
    "        \n",
    "        # 应用权重并沿序列维度取平均\n",
    "        # 数学原理：加权平均公式 (sum(loss * weight)) / sum(weight)\n",
    "        # 实现技巧：mean(dim=1)对每个样本的序列维度做平均\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        \n",
    "        return weighted_loss\n",
    "\"\"\"\n",
    "预测输出：[B,T,V] → permute → [B,V,T]  \n",
    "交叉熵计算：与标签[B,T]对齐 → 得到未加权损失[B,T]\n",
    "应用遮蔽权重[B,T] → 加权平均得到最终损失[B]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0e08c3f-7d8e-47e5-8bbe-97c222e02886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b026086-1703-46c9-9429-7e8eae022f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    # 初始化模型参数（Xavier初始化策略）\n",
    "    def xavier_init_weights(m):\n",
    "        # 原理：Xavier初始化保持各层激活值的方差稳定\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)  # 全连接层权重初始化\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights:\n",
    "                if param.ndim == 2:\n",
    "                    nn.init.xavier_uniform_(param)  # GRU的权重矩阵初始化\n",
    "    \n",
    "    # 应用初始化函数到所有网络层\n",
    "    net.apply(xavier_init_weights)\n",
    "    # 将模型移动到指定设备（CPU/GPU）\n",
    "    net.to(device)\n",
    "    \n",
    "    # 设置优化器（Adam自适应学习率算法）\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)  \n",
    "    \n",
    "    # 定义带遮蔽的交叉熵损失函数（忽略padding位置）\n",
    "    loss = d2l.MaskedSoftmaxCELoss()  \n",
    "    \n",
    "    # 切换到训练模式（影响dropout等层的状态）\n",
    "    net.train()\n",
    "    \n",
    "    # 可视化工具初始化（监控训练过程）\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[0, num_epochs])\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()  # 计时工具\n",
    "        metric = d2l.Accumulator(2)  # 累计损失和有效token数\n",
    "        \n",
    "        for batch in data_iter:\n",
    "            # 数据预处理：将批量数据移动到指定设备\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            \n",
    "            # 构建解码器输入：添加<bos>起始符\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 拼接起始符与右移后的目标序列\n",
    "            \n",
    "            # 前向传播：获取模型输出（编码器-解码器联合计算）\n",
    "            output = net(X, dec_input, X_valid_len)\n",
    "            \n",
    "            # 处理网络输出：解包可能存在的元组结构（如包含注意力权重）\n",
    "            if isinstance(output, tuple):\n",
    "                Y_hat, _ = output  # 取预测结果部分\n",
    "            else:\n",
    "                Y_hat = output\n",
    "            \n",
    "            # 计算损失值（自动处理序列遮蔽）\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            \n",
    "            # 反向传播与梯度裁剪（防止梯度爆炸）\n",
    "            l.sum().backward()  # 损失求和后反向传播\n",
    "            d2l.grad_clipping(net, 1)  # 梯度裁剪阈值设为1（策略参考网页3的训练技巧）\n",
    "            \n",
    "            # 参数更新\n",
    "            optimizer.step()  # 执行优化器更新步骤\n",
    "            optimizer.zero_grad()  # 清空梯度（重要！防止梯度累积）\n",
    "            \n",
    "            # 累计统计指标\n",
    "            metric.add(l.sum(), l.numel())  # 记录总损失和有效token数\n",
    "        \n",
    "        # 周期日志输出\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # 计算平均损失和吞吐量\n",
    "            print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')\n",
    "        animator.add(epoch + 1, (metric[0] / metric[1],))  # 更新训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "136a0682-6150-49e4-adec-c6740348ff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"255.825pt\" height=\"183.887908pt\" viewBox=\"0 0 255.825 183.887908\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-03-25T11:17:28.003085</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.887908 \n",
       "L 255.825 183.887908 \n",
       "L 255.825 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 146.331658 \n",
       "L 239.08125 146.331658 \n",
       "L 239.08125 7.731658 \n",
       "L 43.78125 7.731658 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 43.78125 146.331658 \n",
       "L 43.78125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m7e40485cdb\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"43.78125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(40.6 160.930095) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 76.33125 146.331658 \n",
       "L 76.33125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"76.33125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(69.96875 160.930095) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 108.88125 146.331658 \n",
       "L 108.88125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"108.88125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(99.3375 160.930095) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 141.43125 146.331658 \n",
       "L 141.43125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"141.43125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(131.8875 160.930095) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 173.98125 146.331658 \n",
       "L 173.98125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"173.98125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(164.4375 160.930095) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 206.53125 146.331658 \n",
       "L 206.53125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"206.53125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(196.9875 160.930095) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 239.08125 146.331658 \n",
       "L 239.08125 7.731658 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7e40485cdb\" x=\"239.08125\" y=\"146.331658\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(229.5375 160.930095) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(126.203125 174.60822) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 43.78125 145.299119 \n",
       "L 239.08125 145.299119 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <defs>\n",
       "       <path id=\"m1f1cf8b46b\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m1f1cf8b46b\" x=\"43.78125\" y=\"145.299119\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(20.878125 149.098337) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 43.78125 111.724144 \n",
       "L 239.08125 111.724144 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m1f1cf8b46b\" x=\"43.78125\" y=\"111.724144\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.5 -->\n",
       "      <g transform=\"translate(20.878125 115.523362) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 43.78125 78.149169 \n",
       "L 239.08125 78.149169 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m1f1cf8b46b\" x=\"43.78125\" y=\"78.149169\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(20.878125 81.948387) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 43.78125 44.574194 \n",
       "L 239.08125 44.574194 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m1f1cf8b46b\" x=\"43.78125\" y=\"44.574194\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.5 -->\n",
       "      <g transform=\"translate(20.878125 48.373412) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 43.78125 10.999219 \n",
       "L 239.08125 10.999219 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m1f1cf8b46b\" x=\"43.78125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(20.878125 14.798438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 86.68947) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path d=\"M 44.43225 14.031658 \n",
       "L 45.08325 49.420991 \n",
       "L 45.73425 59.57437 \n",
       "L 47.03625 69.805599 \n",
       "L 48.33825 76.513706 \n",
       "L 49.64025 82.615801 \n",
       "L 50.29125 85.324995 \n",
       "L 51.59325 89.491965 \n",
       "L 53.54625 95.029038 \n",
       "L 54.19725 96.720292 \n",
       "L 54.84825 98.773868 \n",
       "L 58.10325 106.580359 \n",
       "L 60.70725 111.643435 \n",
       "L 61.35825 112.456025 \n",
       "L 62.66025 114.676561 \n",
       "L 63.96225 116.581429 \n",
       "L 64.61325 117.570038 \n",
       "L 65.26425 118.086112 \n",
       "L 65.91525 119.366581 \n",
       "L 67.21725 120.841332 \n",
       "L 69.17025 123.155591 \n",
       "L 69.82125 123.202359 \n",
       "L 70.47225 124.109945 \n",
       "L 71.12325 124.505738 \n",
       "L 73.72725 126.560854 \n",
       "L 74.37825 126.776964 \n",
       "L 75.68025 127.870525 \n",
       "L 76.33125 128.179885 \n",
       "L 76.98225 128.643035 \n",
       "L 77.63325 129.327994 \n",
       "L 78.93525 129.49417 \n",
       "L 79.58625 130.031088 \n",
       "L 80.88825 130.505311 \n",
       "L 81.53925 130.718269 \n",
       "L 82.19025 131.304925 \n",
       "L 82.84125 131.29099 \n",
       "L 83.49225 131.740126 \n",
       "L 84.14325 131.807355 \n",
       "L 84.79425 132.225632 \n",
       "L 86.09625 132.429225 \n",
       "L 86.74725 132.723099 \n",
       "L 87.39825 132.833337 \n",
       "L 88.04925 133.329552 \n",
       "L 89.35125 133.509056 \n",
       "L 90.00225 134.075899 \n",
       "L 90.65325 133.796891 \n",
       "L 91.30425 134.085828 \n",
       "L 93.25725 134.285094 \n",
       "L 93.90825 134.773218 \n",
       "L 97.16325 135.444444 \n",
       "L 97.81425 135.331459 \n",
       "L 98.46525 135.60897 \n",
       "L 99.11625 135.641856 \n",
       "L 100.41825 135.925108 \n",
       "L 102.37125 136.047943 \n",
       "L 103.02225 136.382493 \n",
       "L 103.67325 136.150948 \n",
       "L 104.32425 136.591048 \n",
       "L 104.97525 136.337253 \n",
       "L 108.23025 137.082804 \n",
       "L 108.88125 136.981091 \n",
       "L 109.53225 137.079607 \n",
       "L 110.83425 136.837142 \n",
       "L 111.48525 137.105753 \n",
       "L 112.13625 137.175477 \n",
       "L 112.78725 137.119533 \n",
       "L 113.43825 137.385459 \n",
       "L 114.74025 137.394663 \n",
       "L 115.39125 137.284726 \n",
       "L 116.69325 137.404008 \n",
       "L 117.99525 137.967828 \n",
       "L 119.29725 137.884214 \n",
       "L 119.94825 137.714545 \n",
       "L 121.25025 137.924366 \n",
       "L 122.55225 138.009063 \n",
       "L 123.20325 137.708599 \n",
       "L 124.50525 138.073133 \n",
       "L 125.15625 138.22304 \n",
       "L 126.45825 138.297771 \n",
       "L 127.10925 138.409566 \n",
       "L 127.76025 138.200881 \n",
       "L 130.36425 138.361306 \n",
       "L 132.96825 138.822969 \n",
       "L 133.61925 138.425855 \n",
       "L 134.27025 138.519549 \n",
       "L 135.57225 138.550899 \n",
       "L 136.22325 138.648331 \n",
       "L 136.87425 138.503661 \n",
       "L 138.17625 138.695333 \n",
       "L 140.12925 138.623304 \n",
       "L 141.43125 138.962288 \n",
       "L 142.73325 138.794349 \n",
       "L 144.03525 138.938049 \n",
       "L 145.33725 138.845943 \n",
       "L 145.98825 138.998824 \n",
       "L 146.63925 138.745246 \n",
       "L 147.29025 138.710613 \n",
       "L 147.94125 138.940282 \n",
       "L 150.54525 139.09949 \n",
       "L 151.84725 139.16988 \n",
       "L 153.14925 138.963352 \n",
       "L 153.80025 139.125473 \n",
       "L 155.10225 139.181122 \n",
       "L 155.75325 139.297595 \n",
       "L 156.40425 139.198333 \n",
       "L 157.70625 139.270796 \n",
       "L 159.65925 139.324051 \n",
       "L 160.31025 139.1486 \n",
       "L 160.96125 139.105668 \n",
       "L 162.26325 139.351541 \n",
       "L 163.56525 139.146192 \n",
       "L 164.21625 139.473297 \n",
       "L 164.86725 139.194144 \n",
       "L 167.47125 139.460433 \n",
       "L 168.12225 139.420609 \n",
       "L 168.77325 139.529774 \n",
       "L 170.72625 139.32245 \n",
       "L 173.98125 139.436547 \n",
       "L 174.63225 139.364032 \n",
       "L 175.28325 139.571245 \n",
       "L 177.23625 139.384646 \n",
       "L 178.53825 139.567654 \n",
       "L 179.18925 139.554967 \n",
       "L 179.84025 139.708872 \n",
       "L 180.49125 139.520162 \n",
       "L 186.35025 139.438682 \n",
       "L 187.00125 139.667578 \n",
       "L 187.65225 139.569838 \n",
       "L 188.95425 139.652687 \n",
       "L 189.60525 139.491114 \n",
       "L 190.25625 139.712929 \n",
       "L 190.90725 139.631762 \n",
       "L 191.55825 139.690686 \n",
       "L 192.20925 139.507472 \n",
       "L 192.86025 139.641238 \n",
       "L 193.51125 139.502528 \n",
       "L 194.16225 139.58505 \n",
       "L 195.46425 139.563951 \n",
       "L 196.11525 139.702524 \n",
       "L 196.76625 139.608975 \n",
       "L 198.06825 139.858425 \n",
       "L 198.71925 139.856744 \n",
       "L 199.37025 139.678117 \n",
       "L 201.32325 139.953115 \n",
       "L 201.97425 139.550134 \n",
       "L 202.62525 139.770203 \n",
       "L 203.27625 139.811818 \n",
       "L 203.92725 139.567857 \n",
       "L 204.57825 139.740925 \n",
       "L 205.22925 139.64363 \n",
       "L 205.88025 139.866671 \n",
       "L 206.53125 139.636965 \n",
       "L 207.18225 139.888768 \n",
       "L 207.83325 139.738509 \n",
       "L 211.08825 139.695032 \n",
       "L 213.04125 139.699334 \n",
       "L 214.34325 139.882225 \n",
       "L 214.99425 139.747549 \n",
       "L 216.29625 139.828108 \n",
       "L 216.94725 139.69935 \n",
       "L 217.59825 139.816167 \n",
       "L 219.55125 139.79534 \n",
       "L 220.20225 139.90938 \n",
       "L 221.50425 139.725446 \n",
       "L 222.15525 140.031658 \n",
       "L 222.80625 139.612768 \n",
       "L 223.45725 139.702454 \n",
       "L 224.75925 139.727408 \n",
       "L 235.17525 139.792702 \n",
       "L 235.82625 139.681728 \n",
       "L 236.47725 139.926718 \n",
       "L 237.12825 139.788247 \n",
       "L 237.77925 139.906095 \n",
       "L 239.08125 139.908082 \n",
       "L 239.08125 139.908082 \n",
       "\" clip-path=\"url(#p6b0b18edd8)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 146.331658 \n",
       "L 43.78125 7.731658 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 239.08125 146.331658 \n",
       "L 239.08125 7.731658 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 146.331658 \n",
       "L 239.08125 146.331658 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 7.731658 \n",
       "L 239.08125 7.731658 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p6b0b18edd8\">\n",
       "   <rect x=\"43.78125\" y=\"7.731658\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4f069f2-8415-4bd9-82e6-2f05de90ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 设置模型为评估模式（关闭dropout等训练专用层）\n",
    "    net.eval()  # 原理：预测时不更新参数，保持计算图稳定\n",
    "    \n",
    "    # 将源语句转换为词索引序列，并添加结束符<eos>\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]  # 注意：lower()统一为小写，split()分词处理\n",
    "    \n",
    "    # 创建有效长度张量（实际序列长度）\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)  # 用于编码器掩码\n",
    "    \n",
    "    # 截断/填充处理：统一为固定长度num_steps\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])  # 填充<pad>符号\n",
    "    \n",
    "    # 添加批量维度（batch_size=1）并转换为设备张量\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)  # 形状从(seq_len,)变为(1, seq_len)\n",
    "    \n",
    "    # 编码器前向传播（获取上下文向量）\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)  # 输出包含编码器各时间步状态\n",
    "    \n",
    "    # 初始化解码器状态（使用编码器最终隐藏状态）\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)  # 状态传递原理\n",
    "    \n",
    "    # 构建解码器初始输入（<bos>符号）\n",
    "    dec_X = torch.unsqueeze(\n",
    "        torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device),\n",
    "        dim=0)  # 形状(1,1)，启动解码过程\n",
    "    \n",
    "    # 初始化输出序列和注意力权重容器\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    \n",
    "    # 循环生成目标序列（最多num_steps步）\n",
    "    for _ in range(num_steps):\n",
    "        # 解码器前向传播（Y形状：(1,1, vocab_size)）\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)  # 当前时间步预测\n",
    "        \n",
    "        # 选择概率最高的词作为下一时间步输入（贪心搜索）\n",
    "        dec_X = Y.argmax(dim=2)  # dim=2选择词汇维度，得到预测词索引\n",
    "        \n",
    "        # 提取预测词索引（去除批量维度）\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()  # 转为Python标量\n",
    "        \n",
    "        # 保存注意力权重（用于可视化）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)  # 注意力机制扩展点\n",
    "        \n",
    "        # 遇到结束符则终止生成\n",
    "        if pred == tgt_vocab['<eos>']:  # 提前终止条件\n",
    "            break\n",
    "        \n",
    "        # 收集预测结果\n",
    "        output_seq.append(pred)  # 存储词索引序列\n",
    "    \n",
    "    # 将索引序列转换为目标语言词汇\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq  # 最终输出字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ebdd65a-d180-4931-bf1e-74e30079418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):  \n",
    "    \"\"\"计算BLEU分数，评估机器翻译质量\"\"\"\n",
    "    # 将预测序列和参考序列分割为词列表（处理基础单元）\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    # 获取预测序列和参考序列的长度（用于后续长度惩罚计算）\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    \n",
    "    # 初始化长度惩罚因子（解决短句得分虚高问题）\n",
    "    # 原理：当预测长度<参考长度时施加惩罚\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))  # exp(min(0, 1 - r/c))\n",
    "    \n",
    "    # 遍历1到k元语法（n-gram）计算匹配度\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches = 0  # 有效匹配次数计数器\n",
    "        label_subs = collections.defaultdict(int)  # 存储参考n-gram的出现次数\n",
    "        \n",
    "        # 生成参考序列的所有n-gram并统计出现次数（用于修正精确度）\n",
    "        for i in range(len_label - n + 1):\n",
    "            ngram = ''.join(label_tokens[i:i + n])  # 拼接n-gram作为字典键\n",
    "            label_subs[ngram] += 1  # 记录参考中n-gram出现次数\n",
    "        \n",
    "        # 检测预测序列中的n-gram匹配（考虑重复情况）\n",
    "        for i in range(len_pred - n + 1):\n",
    "            ngram = ''.join(pred_tokens[i:i + n])  \n",
    "            if label_subs[ngram] > 0:  # 当参考中存在该n-gram时\n",
    "                num_matches += 1  # 增加有效匹配计数\n",
    "                label_subs[ngram] -= 1  # 避免重复匹配\n",
    "        \n",
    "        # 计算当前n-gram的修正精确度（分子：有效匹配数，分母：预测n-gram总数）\n",
    "        precision = num_matches / (len_pred - n + 1)\n",
    "        # 加权几何平均（权重系数为0.5^n，参考网页4的加权策略）\n",
    "        score *= math.pow(precision, math.pow(0.5, n))\n",
    "    \n",
    "    return score  # 最终BLEU得分（范围0-1，值越大质量越好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "add63247-6dd9-489d-91f4-484486084b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => le les viens viens je je je je trouve je, bleu 0.000\n",
      "i lost . => le cours je trouve trouve trouve trouve courez oublie-le oublie-le, bleu 0.000\n",
      "he's calm . => le cours je trouve trouve trouve trouve courez oublie-le oublie-le, bleu 0.000\n",
      "i'm home . => le les les j’ai j’ai parti oublie-le oublie-le soyez soyez, bleu 0.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b8ede-c589-431a-bb31-f53419e1561a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
